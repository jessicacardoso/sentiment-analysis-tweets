{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "  <h1 style=\"color:darkblue\"> Classifica√ß√£o de sentimentos nos Tweets - Parte 2üê¶</h1>\n",
    "</div>\n",
    "\n",
    "Nesse notebook, vamos continuar a an√°lise dos tweets, mas agora vamos prev√™-los para tr√™s classes: positivo, negativo e neutro. No notebook anterior, fizemos a an√°lise explorat√≥ria dos tweets e a classifica√ß√£o em cinco classes. Vamos usar a limpeza do notebook anterior e comparar com a vers√£o lematizada dos tweets. \n",
    "\n",
    "Ser√£o treinados dois modelos de classifica√ß√£o: um com os tweets limpos e outro com os tweets lematizados. Ao final, vamos comparar os resultados e verificar se a lematiza√ß√£o dos tweets tem impacto na performance do modelo.\n",
    "\n",
    "Os modelos de classifica√ß√£o que vamos usar s√£o os mesmos do notebook anterior:\n",
    "- Regress√£o Log√≠stica\n",
    "- Naive Bayes\n",
    "- Floresta Aleat√≥ria\n",
    "- SVM Linear\n",
    "\n",
    "Al√©m disso, vamos usar a t√©cnica de vetoriza√ß√£o dos textos com o TF-IDF. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import (\n",
    "    make_scorer,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/Corona_NLP_train.csv\", encoding=\"latin1\")\n",
    "df = df[[\"OriginalTweet\", \"Sentiment\"]]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Sentiment\"] = df[\"Sentiment\"].replace(\n",
    "    {\"Extremely Negative\": \"Negative\", \"Extremely Positive\": \"Positive\"}\n",
    ")\n",
    "df[\"Sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepara√ß√£o dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    return (\n",
    "        text.str.lower()\n",
    "        # remove links\n",
    "        .str.replace(r\"https\\S+|www\\S+|https\\S+\", \"\", regex=True)\n",
    "        # remove usernames\n",
    "        .str.replace(r\"\\@\\w+\", \"\", regex=True)\n",
    "        # remove hashtags\n",
    "        .str.replace(r\"\\#(\\w+)\", \"\", regex=True)\n",
    "        # remove non-ascii characters\n",
    "        .str.normalize(\"NFKD\")\n",
    "        .str.encode(\"ascii\", errors=\"ignore\")\n",
    "        .str.decode(\"utf-8\")\n",
    "        # manter apenas letras, espa√ßos e ap√≥strofos\n",
    "        .str.replace(r\"[^a-z\\s\\']\", \"\", regex=True)\n",
    "        # remove excesso de espa√ßos\n",
    "        .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "        # remove espa√ßos no come√ßo e no fim\n",
    "        .str.strip()\n",
    "    )\n",
    "\n",
    "\n",
    "df[\"CleanTweet\"] = preprocess_text(df[\"OriginalTweet\"])\n",
    "\n",
    "# Remover palavras que aparecem apenas uma vez\n",
    "words = df[\"CleanTweet\"].str.cat(sep=\" \").split()\n",
    "types = Counter(words)\n",
    "hapax = set([word for word, count in types.items() if count <= 1])\n",
    "\n",
    "df[\"CleanTweet\"] = df[\"CleanTweet\"].apply(\n",
    "    lambda text: \" \".join([word for word in text.split() if word not in hapax])\n",
    ")\n",
    "\n",
    "# Manter apenas tweets com mais de 2 palavras\n",
    "df = df.loc[df[\"CleanTweet\"].str.split().str.len() > 2]\n",
    "df = df.drop_duplicates(subset=[\"CleanTweet\", \"Sentiment\"])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = nlp.pipe(df[\"CleanTweet\"])\n",
    "\n",
    "df[\"Lemmatized\"] = [\n",
    "    \" \".join([token.lemma_ for token in doc])\n",
    "    for doc in tqdm(docs, total=len(df), desc=\"Lemmatizing\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\n",
    "    df[\"Lemmatized\"].duplicated(keep=False), [\"CleanTweet\", \"Sentiment\"]\n",
    "].sort_values(\"CleanTweet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao aplicar a lematiza√ß√£o notamos *tweets* duplicados, por isso, vamos remover esses *tweets* duplicados considerando apenas o texto lematizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=[\"Lemmatized\", \"Sentiment\"])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos de Classifica√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"MultinomialNB\": MultinomialNB(),\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=1000),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "    \"LinearSVC\": LinearSVC(dual=\"auto\", random_state=42),\n",
    "}\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"Sentiment\"])\n",
    "y = df[\"Sentiment\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 1: Tweets Limpos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweet_vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "X_train_vectorized = clean_tweet_vectorizer.fit_transform(X_train[\"CleanTweet\"])\n",
    "X_test_vectorized = clean_tweet_vectorizer.transform(X_test[\"CleanTweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "print(\"LIMPEZA SEM LEMA:\")\n",
    "for model_name, model in tqdm(models.items(), desc=\"Training models\"):\n",
    "    scores = cross_validate(\n",
    "        model,\n",
    "        X_train_vectorized,\n",
    "        y_train,\n",
    "        cv=5,\n",
    "        scoring={\n",
    "            \"accuracy\": make_scorer(accuracy_score),\n",
    "            \"precision\": make_scorer(precision_score, average=\"weighted\"),\n",
    "            \"recall\": make_scorer(recall_score, average=\"weighted\"),\n",
    "            \"f1\": make_scorer(f1_score, average=\"weighted\"),\n",
    "        },\n",
    "        return_train_score=True,\n",
    "    )\n",
    "\n",
    "    results[model_name] = scores\n",
    "\n",
    "    print(f\"{model_name:=^55}\")\n",
    "    print(\n",
    "        f\"{'subset':10}\",\n",
    "        f\"{'accuracy':>10}\",\n",
    "        f\"{'precision':>10}\",\n",
    "        f\"{'recall':>10}\",\n",
    "        f\"{'f1':>10}\",\n",
    "    )\n",
    "    print(\n",
    "        f\"{'train':10}\",\n",
    "        f\"{scores['train_accuracy'].mean():10.2f}\",\n",
    "        f\"{scores['train_precision'].mean():10.2f}\",\n",
    "        f\"{scores['train_recall'].mean():10.2f}\",\n",
    "        f\"{scores['train_f1'].mean():10.2f}\",\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"{'test':10}\",\n",
    "        f\"{scores['test_accuracy'].mean():10.2f}\",\n",
    "        f\"{scores['test_precision'].mean():10.2f}\",\n",
    "        f\"{scores['test_recall'].mean():10.2f}\",\n",
    "        f\"{scores['test_f1'].mean():10.2f}\",\n",
    "    )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, validamos os modelos nos dados de teste e comparamos os resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model in models.items():\n",
    "    model.fit(X_train_vectorized, y_train)\n",
    "    y_pred = model.predict(X_test_vectorized)\n",
    "    print(f\"{model_name:=^55}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os modelos SVM Linear e Regress√£o Log√≠stica tiveram os melhores resultados. Sendo o primeiro com F1 m√©dio ponderado de 0.81 e o segundo com 0.80."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 2: Tweets limpos e lematizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "\n",
    "X_train_vectorized = lemmatized_vectorizer.fit_transform(X_train[\"Lemmatized\"])\n",
    "X_test_vectorized = lemmatized_vectorizer.transform(X_test[\"Lemmatized\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "print(\"LIMPEZA COM LEMA:\")\n",
    "for model_name, model in tqdm(models.items(), desc=\"Training models\"):\n",
    "    scores = cross_validate(\n",
    "        model,\n",
    "        X_train_vectorized,\n",
    "        y_train,\n",
    "        cv=5,\n",
    "        scoring={\n",
    "            \"accuracy\": make_scorer(accuracy_score),\n",
    "            \"precision\": make_scorer(precision_score, average=\"weighted\"),\n",
    "            \"recall\": make_scorer(recall_score, average=\"weighted\"),\n",
    "            \"f1\": make_scorer(f1_score, average=\"weighted\"),\n",
    "        },\n",
    "        return_train_score=True,\n",
    "    )\n",
    "\n",
    "    results[model_name] = scores\n",
    "\n",
    "    print(f\"{model_name:=^55}\")\n",
    "    print(\n",
    "        f\"{'subset':10}\",\n",
    "        f\"{'accuracy':>10}\",\n",
    "        f\"{'precision':>10}\",\n",
    "        f\"{'recall':>10}\",\n",
    "        f\"{'f1':>10}\",\n",
    "    )\n",
    "    print(\n",
    "        f\"{'train':10}\",\n",
    "        f\"{scores['train_accuracy'].mean():10.2f}\",\n",
    "        f\"{scores['train_precision'].mean():10.2f}\",\n",
    "        f\"{scores['train_recall'].mean():10.2f}\",\n",
    "        f\"{scores['train_f1'].mean():10.2f}\",\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"{'test':10}\",\n",
    "        f\"{scores['test_accuracy'].mean():10.2f}\",\n",
    "        f\"{scores['test_precision'].mean():10.2f}\",\n",
    "        f\"{scores['test_recall'].mean():10.2f}\",\n",
    "        f\"{scores['test_f1'].mean():10.2f}\",\n",
    "    )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model in models.items():\n",
    "    model.fit(X_train_vectorized, y_train)\n",
    "    y_pred = model.predict(X_test_vectorized)\n",
    "    print(f\"{model_name:=^55}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os valores de F1 m√©dio ponderado continuaram sendo os melhores para os modelos SVM Linear e Regress√£o Log√≠stica, ambos com 0.79. Podemos observar que classificar os *tweets* em tr√™s classes √© mais f√°cil do que em cinco classes, pois os modelos tiveram um desempenho melhor."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tweets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
